{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMzBtcm9pBLYhmiuAjDFc9x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lKqGNuEJ6Yux"},"outputs":[],"source":["# @title\n","# pip\n","\n","!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n","!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai"]},{"cell_type":"code","source":["# @title\n","# imports\n","\n","import os\n","import json\n","import requests\n","import gradio as gr\n","from IPython.display import Markdown, display, update_display\n","from openai import OpenAI\n","from google.colab import drive\n","from huggingface_hub import login\n","from google.colab import userdata\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n","import torch"],"metadata":{"id":"78rOjizs6h6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# constants\n","\n","LLAMA = \"meta-llama/Llama-3.1-8B-Instruct\"\n","DRIVE_PATH = '/content/drive/MyDrive/'\n","drive.mount('/content/drive/', force_remount=True)"],"metadata":{"id":"f7pky1xC6lu-","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# sign in to HuggingFace\n","\n","login(userdata.get('HF_TOKEN'), add_to_git_credential=True)"],"metadata":{"id":"5PNg7C2A_d3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# sign in to openAI\n","\n","openai = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"],"metadata":{"id":"wNw7fsWU_hIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# prompts\n","\n","system_prompt = \"You are a helpful AI assistant, Your core mission is to produce synthetic high-quality, diverse datasets tailored precisely to a user's needs.\"\n","system_prompt += \"For Example: 'I need 25 customer support chat dialogues about internet connectivity issues.' Each dialogue should be between a customer and a support agent, and include at least 3-5 turns per participant.\"\n","system_prompt += \"The output should be a JSON array.\"\n","user_prompt = \"I need 10 customer reviews on a vaccume product.\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": user_prompt}\n","]"],"metadata":{"id":"gsWs2SbJ_mLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# quantization\n","\n","quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_quant_type=\"nf4\"\n",")"],"metadata":{"id":"wKCguZoLDdZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# tokenize\n","\n","tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n","tokenizer.pad_token = tokenizer.eos_token\n"],"metadata":{"id":"Ff2uChsAJXk7","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# build model\n","\n","inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","streamer = TextStreamer(tokenizer)\n","model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\")\n","# model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n","\n","outputs = model.generate(inputs, streamer=streamer, max_new_tokens=2000)"],"metadata":{"id":"tdkvfSKHJ3cr","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# print response\n","\n","response = tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"CcuwIrcrLThe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# write output to google drive\n","\n","response_folder = os.path.join(DRIVE_PATH, \"04_Projects\", \"Python Projects\",  \"synthetic_data_generator\", \"Llama_Responses\")\n","if not os.path.exists(response_folder):\n","    os.makedirs(response_folder)\n","    print(f\"Created folder: {response_folder}\")\n","else:\n","    print(f\"Using existing folder: {response_folder}\")\n","\n","def save_response_to_drive(file_content, filename):\n","    \"\"\"\n","    Saves a string to a file in the mounted Google Drive.\n","    \"\"\"\n","    try:\n","        # Construct the full file path within your mounted Drive\n","        full_path = os.path.join(response_folder, filename)\n","\n","        with open(full_path, \"w\") as f:\n","            f.write(file_content)\n","\n","        print(f\"File '{filename}' saved successfully to Google Drive at: {full_path}\")\n","        return True\n","    except Exception as e:\n","        print(f\"Error saving file to Google Drive: {e}\")\n","        return False"],"metadata":{"id":"UbIZ2bd846t5","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","save_response_to_drive(response, \"vacume_reviews.txt\")"],"metadata":{"id":"MSDCZR1y48rb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# build combined function\n","\n","def generate(prompt):\n","  messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": prompt}\n","  ]\n","  inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n","  outputs = model.generate(inputs, streamer=streamer, max_new_tokens=5000)\n","  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","  yield response"],"metadata":{"id":"JCyaYyNwaliR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# build UI\n","\n","ui = gr.Interface(\n","    fn=generate,\n","    inputs=[\"text\"],\n","    outputs=[\"text\"],\n","    allow_flagging=\"never\"\n",")\n","\n","ui.launch()"],"metadata":{"id":"MBg_6KAbZ3OX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","\n"],"metadata":{"id":"vZBNba6fbaDQ"},"execution_count":null,"outputs":[]}]}